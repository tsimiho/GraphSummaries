{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../gmn_config/'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from gmn_config.graph_utils import *\n",
    "\n",
    "from gmn_config.evaluation import compute_similarity, auc\n",
    "from gmn_config.loss import pairwise_loss, triplet_loss\n",
    "from gmn_config.gmn_utils import *\n",
    "from gmn_config.configure_cosine import *\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "\n",
    "# Print configure\n",
    "config = get_default_config()\n",
    "for k, v in config.items():\n",
    "    print(\"%s= %s\" % (k, v))\n",
    "\n",
    "# Set random seeds\n",
    "seed = config[\"seed\"]\n",
    "random.seed(seed)\n",
    "np.random.seed(seed + 1)\n",
    "# torch.manual_seed(seed + 2)\n",
    "torch.backends.cudnn.deterministic = False\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "\n",
    "training_set, validation_set = build_datasets(config)\n",
    "\n",
    "if config[\"training\"][\"mode\"] == \"pair\":\n",
    "    training_data_iter = training_set.pairs(config[\"training\"][\"batch_size\"])\n",
    "    first_batch_graphs, _ = next(training_data_iter)\n",
    "else:\n",
    "    training_data_iter = training_set.triplets(config[\"training\"][\"batch_size\"])\n",
    "    first_batch_graphs = next(training_data_iter)\n",
    "\n",
    "node_feature_dim = first_batch_graphs.node_features.shape[-1]\n",
    "edge_feature_dim = first_batch_graphs.edge_features.shape[-1]\n",
    "\n",
    "gmn, optimizer = build_model(config, node_feature_dim, edge_feature_dim)\n",
    "gmn.load_state_dict(torch.load(\"../gmn_config/model64_5.pth\"))\n",
    "gmn.to(device)\n",
    "gmn.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import torch\n",
    "from torch.nn import Linear\n",
    "\n",
    "import torch_geometric\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.nn import GraphConv, dense_mincut_pool\n",
    "from torch_geometric import utils\n",
    "from torch_geometric.nn import Sequential\n",
    "from torch_geometric.nn.conv.gcn_conv import gcn_norm\n",
    "\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from utils.eval_metrics import *\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'Cora'\n",
    "path = osp.join('..', 'data', dataset)\n",
    "dataset = Planetoid(path, dataset, transform=T.NormalizeFeatures())\n",
    "data = dataset[0]\n",
    "\n",
    "# data.edge_index, data.edge_weight = gcn_norm(  \n",
    "#                 data.edge_index, data.edge_weight, data.num_nodes,\n",
    "#                 add_self_loops=False, dtype=data.x.dtype)\n",
    "\n",
    "delta = 0.85\n",
    "edge_index, edge_weight = utils.get_laplacian(data.edge_index, data.edge_weight, normalization='sym')\n",
    "L = utils.to_dense_adj(edge_index, edge_attr=edge_weight)\n",
    "A = torch.eye(data.num_nodes) - delta*L\n",
    "data.edge_index, data.edge_weight = utils.dense_to_sparse(A)\n",
    "\n",
    "data = data.to(device)\n",
    "original_data = Data(x=reduce_dimensions(data.x.numpy()), edge_index=data.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinCutNet(torch.nn.Module):\n",
    "    def __init__(self, \n",
    "                 mp_units,\n",
    "                 mp_act,\n",
    "                 in_channels, \n",
    "                 n_clusters, \n",
    "                 mlp_units=[],\n",
    "                 mlp_act=\"Identity\"):\n",
    "        super().__init__()\n",
    "        \n",
    "        mp_act = getattr(torch.nn, mp_act)(inplace=True)\n",
    "        mlp_act = getattr(torch.nn, mlp_act)(inplace=True)\n",
    "        \n",
    "        mp = [\n",
    "            (GraphConv(in_channels, mp_units[0]), 'x, edge_index, edge_weight -> x'),\n",
    "            mp_act\n",
    "        ]\n",
    "        for i in range(len(mp_units)-1):\n",
    "            mp.append((GraphConv(mp_units[i], mp_units[i+1]), 'x, edge_index, edge_weight -> x'))\n",
    "            mp.append(mp_act)\n",
    "        self.mp = Sequential('x, edge_index, edge_weight', mp)\n",
    "        out_chan = mp_units[-1]\n",
    "        \n",
    "        self.mlp = torch.nn.Sequential()\n",
    "        for units in mlp_units:\n",
    "            self.mlp.append(Linear(out_chan, units))\n",
    "            out_chan = units\n",
    "            self.mlp.append(mlp_act)\n",
    "        self.mlp.append(Linear(out_chan, n_clusters))\n",
    "        \n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight, epoch, max_epochs, l_value=0.0):\n",
    "        x = self.mp(x, edge_index, edge_weight) \n",
    "        s = self.mlp(x) \n",
    "        adj = utils.to_dense_adj(edge_index, edge_attr=edge_weight)\n",
    "        x_pooled, adj_pooled, mc_loss, o_loss = dense_mincut_pool(x, adj, s)\n",
    "        \n",
    "        if l_value != 0.0:\n",
    "            edge_index_pool = utils.dense_to_sparse(adj_pooled)[0]\n",
    "            clustered_data = torch_geometric.data.Data(x=x_pooled[0], edge_index=edge_index_pool)\n",
    "            sim = similarity(gmn, config, original_data, clustered_data)\n",
    "            sim_loss = - l_value * ((1 + sim)/2)\n",
    "        else:\n",
    "            sim = 1.0\n",
    "            sim_loss = -1.0\n",
    "                \n",
    "        loss = (mc_loss + o_loss)/(-sim_loss)\n",
    "                \n",
    "        return torch.softmax(s, dim=-1), loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MinCutNet([64], \"ELU\", dataset.num_features, dataset.num_classes).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "\n",
    "\n",
    "def train(epoch, max_epochs, l_value=0.0):\n",
    "    global best_sim\n",
    "    model.train()\n",
    "    optimizer.zero_grad()  \n",
    "    _, loss = model(data.x, data.edge_index, data.edge_weight, epoch, max_epochs, l_value)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(epoch, max_epochs, l_value=0.0):\n",
    "    model.eval()\n",
    "    clust, _ = model(data.x, data.edge_index, data.edge_weight, epoch, max_epochs, l_value)\n",
    "    return eval_metrics(data.y.cpu(), clust.max(1)[1].cpu())\n",
    "    \n",
    "\n",
    "for epoch in range(1, 751):\n",
    "    train_loss = train(epoch, 1001)\n",
    "    acc, nmi = test(epoch, 1001)\n",
    "    if epoch % 50 == 0:\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {train_loss:.4f}, NMI: {nmi:.3f}, ACC: {acc:.3f}')\n",
    "        \n",
    "torch.save(model.state_dict(), \"mincut.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"mincut.pth\"))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(1, 751):\n",
    "    train_loss = train(epoch, 751, l_value=1.0)\n",
    "    acc, nmi = test(epoch, 751, l_value=1.0)\n",
    "    if epoch % 50 == 0:\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {train_loss:.4f}, NMI: {nmi:.3f}, ACC: {acc:.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
