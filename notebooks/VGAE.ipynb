{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import VGAE, GCNConv\n",
    "from torch_geometric.utils import train_test_split_edges\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn.models import InnerProductDecoder, VGAE\n",
    "from torch_geometric.nn.conv import GCNConv\n",
    "from torch_geometric.utils import negative_sampling, remove_self_loops, add_self_loops\n",
    "import os.path as osp\n",
    "from torch.optim import Adam\n",
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "from sklearn.cluster import KMeans\n",
    "import torch_geometric\n",
    "\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from utils.eval_metrics import *\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'Cora'\n",
    "path = osp.join('..', 'data', dataset)\n",
    "dataset = Planetoid(path, dataset, transform=T.NormalizeFeatures())\n",
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNEncoder(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GCNEncoder, self).__init__()\n",
    "        self.gcn_shared = GCNConv(in_channels, hidden_channels)\n",
    "        self.gcn_mu = GCNConv(hidden_channels, out_channels)\n",
    "        self.gcn_logvar = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.gcn_shared(x, edge_index))\n",
    "        mu = self.gcn_mu(x, edge_index)\n",
    "        logvar = self.gcn_logvar(x, edge_index)\n",
    "        return mu, logvar\n",
    "\n",
    "\n",
    "class DeepVGAE(VGAE):\n",
    "    def __init__(self, enc_in_channels, enc_hidden_channels, enc_out_channels):\n",
    "        super(DeepVGAE, self).__init__(encoder=GCNEncoder(enc_in_channels,\n",
    "                                                          enc_hidden_channels,\n",
    "                                                          enc_out_channels),\n",
    "                                       decoder=InnerProductDecoder())\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        z = self.encode(x, edge_index)\n",
    "        adj_pred = self.decoder.forward_all(z)\n",
    "        return adj_pred\n",
    "\n",
    "    def loss(self, x, pos_edge_index, all_edge_index):\n",
    "        z = self.encode(x, pos_edge_index)\n",
    "\n",
    "        pos_loss = -torch.log(\n",
    "            self.decoder(z, pos_edge_index, sigmoid=True) + 1e-15).mean()\n",
    "\n",
    "        all_edge_index_tmp, _ = remove_self_loops(all_edge_index)\n",
    "        all_edge_index_tmp, _ = add_self_loops(all_edge_index_tmp)\n",
    "\n",
    "        neg_edge_index = negative_sampling(all_edge_index_tmp, z.size(0), pos_edge_index.size(1))\n",
    "        neg_loss = -torch.log(1 - self.decoder(z, neg_edge_index, sigmoid=True) + 1e-15).mean()\n",
    "\n",
    "        kl_loss = 1 / x.size(0) * self.kl_loss()\n",
    "\n",
    "        return pos_loss + neg_loss + kl_loss\n",
    "\n",
    "    def single_test(self, x, train_pos_edge_index, test_pos_edge_index, test_neg_edge_index):\n",
    "        with torch.no_grad():\n",
    "            z = self.encode(x, train_pos_edge_index)\n",
    "        roc_auc_score, average_precision_score = self.test(z, test_pos_edge_index, test_neg_edge_index)\n",
    "        return roc_auc_score, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 050, Loss: 1.3726, NMI: 0.1615, ACC: 0.3493\n",
      "Epoch: 100, Loss: 1.0362, NMI: 0.3568, ACC: 0.4815\n",
      "Epoch: 150, Loss: 0.9476, NMI: 0.4690, ACC: 0.6329\n",
      "Epoch: 200, Loss: 0.9236, NMI: 0.4905, ACC: 0.6137\n",
      "Epoch: 250, Loss: 0.9012, NMI: 0.5023, ACC: 0.6488\n",
      "Epoch: 300, Loss: 0.8866, NMI: 0.5119, ACC: 0.6739\n",
      "Epoch: 350, Loss: 0.8804, NMI: 0.5007, ACC: 0.6636\n",
      "Epoch: 400, Loss: 0.8699, NMI: 0.4975, ACC: 0.6617\n",
      "Epoch: 450, Loss: 0.8724, NMI: 0.4885, ACC: 0.6606\n",
      "Epoch: 500, Loss: 0.8624, NMI: 0.4967, ACC: 0.6784\n",
      "Epoch: 550, Loss: 0.8590, NMI: 0.4957, ACC: 0.6673\n",
      "Epoch: 600, Loss: 0.8512, NMI: 0.4749, ACC: 0.6529\n",
      "Epoch: 650, Loss: 0.8565, NMI: 0.4935, ACC: 0.6673\n",
      "Epoch: 700, Loss: 0.8459, NMI: 0.4769, ACC: 0.6403\n",
      "Epoch: 750, Loss: 0.8450, NMI: 0.4613, ACC: 0.5720\n"
     ]
    }
   ],
   "source": [
    "model = DeepVGAE(enc_in_channels=data.num_features, enc_hidden_channels=128, enc_out_channels=64).to(device)\n",
    "optimizer = Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(1,751):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(data.x, data.edge_index)\n",
    "    loss = model.recon_loss(z, data.edge_index) + (1 / data.num_nodes) * model.kl_loss()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 50 == 0:\n",
    "        model.eval()\n",
    "        z = model.encode(data.x, data.edge_index)\n",
    "        kmeans = KMeans(n_clusters=dataset.num_classes, n_init=10, random_state=0).fit(z.detach().cpu().numpy())\n",
    "        predicted_labels = torch.tensor(kmeans.labels_, device=device)\n",
    "        acc, nmi = eval_metrics(data.y, predicted_labels)\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {loss.item():.4f}, NMI: {nmi:.4f}, ACC: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[7, 64], edge_index=[2, 42])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "z = model.encode(data.x, data.edge_index).detach().cpu().numpy()\n",
    "\n",
    "kmeans = KMeans(n_clusters=dataset.num_classes, n_init=10, random_state=0)\n",
    "predicted_clusters = kmeans.fit_predict(z)\n",
    "\n",
    "num_clusters = dataset.num_classes\n",
    "cluster_adj_matrix = np.zeros((num_clusters, num_clusters))\n",
    "\n",
    "for i in range(data.edge_index.size(1)):\n",
    "    src, dest = data.edge_index[:, i]\n",
    "    src_cluster = predicted_clusters[src.item()]\n",
    "    dest_cluster = predicted_clusters[dest.item()]\n",
    "    if src_cluster != dest_cluster:\n",
    "        cluster_adj_matrix[src_cluster, dest_cluster] = 1\n",
    "        cluster_adj_matrix[dest_cluster, src_cluster] = 1\n",
    "\n",
    "cluster_edge_index = torch.tensor(np.array(np.nonzero(cluster_adj_matrix)), dtype=torch.long)\n",
    "cluster_centers = torch.tensor(kmeans.cluster_centers_, dtype=torch.float)\n",
    "\n",
    "clustered_data = torch_geometric.data.Data(x=cluster_centers, edge_index=cluster_edge_index)\n",
    "print(clustered_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
