{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder= {'node_hidden_sizes': [64], 'node_feature_dim': 1, 'edge_hidden_sizes': [4]}\n",
      "aggregator= {'node_hidden_sizes': [128], 'graph_transform_sizes': [128], 'input_size': [64], 'gated': True, 'aggregation_type': 'sum'}\n",
      "graph_embedding_net= {'node_state_dim': 64, 'edge_state_dim': 4, 'edge_hidden_sizes': [128, 128], 'node_hidden_sizes': [128], 'n_prop_layers': 5, 'share_prop_params': True, 'edge_net_init_scale': 0.1, 'node_update_type': 'gru', 'use_reverse_direction': True, 'reverse_dir_param_different': False, 'layer_norm': False, 'prop_type': 'matching'}\n",
      "graph_matching_net= {'node_state_dim': 64, 'edge_state_dim': 4, 'edge_hidden_sizes': [128, 128], 'node_hidden_sizes': [128], 'n_prop_layers': 5, 'share_prop_params': True, 'edge_net_init_scale': 0.1, 'node_update_type': 'gru', 'use_reverse_direction': True, 'reverse_dir_param_different': False, 'layer_norm': False, 'prop_type': 'matching', 'similarity': 'dotproduct'}\n",
      "model_type= matching\n",
      "data= {'problem': 'graph_edit_distance', 'dataset_params': {'n_nodes_range': [20, 20], 'p_edge_range': [0.2, 0.2], 'n_changes_positive': 1, 'n_changes_negative': 2, 'validation_dataset_size': 1000}}\n",
      "training= {'batch_size': 20, 'learning_rate': 0.0001, 'mode': 'pair', 'loss': 'cosine', 'margin': 1.0, 'graph_vec_regularizer_weight': 1e-06, 'clip_value': 10.0, 'n_training_steps': 100000, 'print_after': 100, 'eval_after': 10}\n",
      "evaluation= {'batch_size': 20}\n",
      "seed= 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GraphMatchingNet(\n",
       "  (_encoder): GraphEncoder(\n",
       "    (MLP1): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "    )\n",
       "    (MLP2): Sequential(\n",
       "      (0): Linear(in_features=4, out_features=4, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (_aggregator): GraphAggregator(\n",
       "    (MLP1): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "    )\n",
       "    (MLP2): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (_prop_layers): ModuleList(\n",
       "    (0-4): 5 x GraphPropMatchingLayer(\n",
       "      (_message_net): Sequential(\n",
       "        (0): Linear(in_features=132, out_features=128, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (_reverse_message_net): Sequential(\n",
       "        (0): Linear(in_features=132, out_features=128, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (GRU): GRU(192, 64)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../gmn_config/'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from gmn_config.graph_utils import *\n",
    "\n",
    "from gmn_config.evaluation import compute_similarity, auc\n",
    "from gmn_config.loss import pairwise_loss, triplet_loss\n",
    "from gmn_config.gmn_utils import *\n",
    "from gmn_config.configure_cosine import *\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "\n",
    "# Print configure\n",
    "config = get_default_config()\n",
    "for k, v in config.items():\n",
    "    print(\"%s= %s\" % (k, v))\n",
    "\n",
    "# Set random seeds\n",
    "seed = config[\"seed\"]\n",
    "random.seed(seed)\n",
    "np.random.seed(seed + 1)\n",
    "torch.manual_seed(seed + 2)\n",
    "torch.backends.cudnn.deterministic = False\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "\n",
    "training_set, validation_set = build_datasets(config)\n",
    "\n",
    "if config[\"training\"][\"mode\"] == \"pair\":\n",
    "    training_data_iter = training_set.pairs(config[\"training\"][\"batch_size\"])\n",
    "    first_batch_graphs, _ = next(training_data_iter)\n",
    "else:\n",
    "    training_data_iter = training_set.triplets(config[\"training\"][\"batch_size\"])\n",
    "    first_batch_graphs = next(training_data_iter)\n",
    "\n",
    "node_feature_dim = first_batch_graphs.node_features.shape[-1]\n",
    "edge_feature_dim = first_batch_graphs.edge_features.shape[-1]\n",
    "\n",
    "gmn, optimizer = build_model(config, node_feature_dim, edge_feature_dim)\n",
    "gmn.load_state_dict(torch.load(\"../gmn_config/model64new.pth\"))\n",
    "gmn.to(device)\n",
    "gmn.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import torch\n",
    "from torch.nn import Linear\n",
    "\n",
    "import torch_geometric\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.nn import GraphConv, dense_mincut_pool\n",
    "from torch_geometric import utils\n",
    "from torch_geometric.nn import Sequential\n",
    "from torch_geometric.nn.conv.gcn_conv import gcn_norm\n",
    "\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from utils.eval_metrics import *\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'Cora'\n",
    "path = osp.join('..', 'data', dataset)\n",
    "dataset = Planetoid(path, dataset, transform=T.NormalizeFeatures())\n",
    "data = dataset[0]\n",
    "\n",
    "# data.edge_index, data.edge_weight = gcn_norm(  \n",
    "#                 data.edge_index, data.edge_weight, data.num_nodes,\n",
    "#                 add_self_loops=False, dtype=data.x.dtype)\n",
    "\n",
    "delta = 0.85\n",
    "edge_index, edge_weight = utils.get_laplacian(data.edge_index, data.edge_weight, normalization='sym')\n",
    "L = utils.to_dense_adj(edge_index, edge_attr=edge_weight)\n",
    "A = torch.eye(data.num_nodes) - delta*L\n",
    "data.edge_index, data.edge_weight = utils.dense_to_sparse(A)\n",
    "\n",
    "data = data.to(device)\n",
    "original_data = Data(x=reduce_dimensions(data.x.numpy()), edge_index=data.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinCutNet(torch.nn.Module):\n",
    "    def __init__(self, \n",
    "                 mp_units,\n",
    "                 mp_act,\n",
    "                 in_channels, \n",
    "                 n_clusters, \n",
    "                 mlp_units=[],\n",
    "                 mlp_act=\"Identity\"):\n",
    "        super().__init__()\n",
    "        \n",
    "        mp_act = getattr(torch.nn, mp_act)(inplace=True)\n",
    "        mlp_act = getattr(torch.nn, mlp_act)(inplace=True)\n",
    "        \n",
    "        mp = [\n",
    "            (GraphConv(in_channels, mp_units[0]), 'x, edge_index, edge_weight -> x'),\n",
    "            mp_act\n",
    "        ]\n",
    "        for i in range(len(mp_units)-1):\n",
    "            mp.append((GraphConv(mp_units[i], mp_units[i+1]), 'x, edge_index, edge_weight -> x'))\n",
    "            mp.append(mp_act)\n",
    "        self.mp = Sequential('x, edge_index, edge_weight', mp)\n",
    "        out_chan = mp_units[-1]\n",
    "        \n",
    "        self.mlp = torch.nn.Sequential()\n",
    "        for units in mlp_units:\n",
    "            self.mlp.append(Linear(out_chan, units))\n",
    "            out_chan = units\n",
    "            self.mlp.append(mlp_act)\n",
    "        self.mlp.append(Linear(out_chan, n_clusters))\n",
    "        \n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        x = self.mp(x, edge_index, edge_weight) \n",
    "        s = self.mlp(x) \n",
    "        adj = utils.to_dense_adj(edge_index, edge_attr=edge_weight)\n",
    "        x_pool, adj_pool, mc_loss, o_loss = dense_mincut_pool(x, adj, s)\n",
    "        \n",
    "        return torch.softmax(s, dim=-1), mc_loss, o_loss, x_pool, adj_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 050, Loss: -0.5216, NMI: 0.383, ACC: 0.537\n",
      "Epoch: 100, Loss: -0.8938, NMI: 0.439, ACC: 0.574\n",
      "Epoch: 150, Loss: -0.9123, NMI: 0.444, ACC: 0.577\n",
      "Epoch: 200, Loss: -0.9182, NMI: 0.445, ACC: 0.577\n"
     ]
    }
   ],
   "source": [
    "model = MinCutNet([64], \"ELU\", dataset.num_features, dataset.num_classes).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    _, mc_loss, o_loss, x_pool, adj_pool = model(data.x, data.edge_index, data.edge_weight)\n",
    "    loss = mc_loss + o_loss\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test():\n",
    "    model.eval()\n",
    "    clust, _, _, _, _ = model(data.x, data.edge_index, data.edge_weight)\n",
    "    return eval_metrics(data.y.cpu(), clust.max(1)[1].cpu())\n",
    "    \n",
    "\n",
    "patience = 50\n",
    "best_nmi = 0\n",
    "for epoch in range(1, 1001):\n",
    "    train_loss = train()\n",
    "    acc, nmi = test()\n",
    "    if epoch % 50 == 0:\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {train_loss:.4f}, NMI: {nmi:.3f}, ACC: {acc:.3f}')\n",
    "    if nmi > best_nmi:\n",
    "        best_nmi = nmi\n",
    "        patience = 50\n",
    "    else:\n",
    "        patience -= 1\n",
    "    if patience == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8706, grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "_, _, _, x_pool, adj_pool = model(data.x, data.edge_index, data.edge_weight)\n",
    "edge_index_pool = utils.dense_to_sparse(adj_pool)[0]\n",
    "clustered_data = torch_geometric.data.Data(x=x_pool[0], edge_index=edge_index_pool)\n",
    "original_data = Data(x=reduce_dimensions(data.x.numpy()), edge_index=data.edge_index)\n",
    "sim = similarity(gmn, config, original_data, clustered_data)\n",
    "print(sim)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
