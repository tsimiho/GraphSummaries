{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../gmn_config/'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from gmn_config.graph_utils import *\n",
    "\n",
    "from gmn_config.evaluation import compute_similarity, auc\n",
    "from gmn_config.loss import pairwise_loss, triplet_loss\n",
    "from gmn_config.gmn_utils import *\n",
    "from gmn_config.configure_cosine import *\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "\n",
    "config = get_default_config()\n",
    "\n",
    "# torch.manual_seed(seed + 2)\n",
    "torch.backends.cudnn.deterministic = False\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "gmn, optimizer = build_model(config, 64, 4)\n",
    "gmn.load_state_dict(torch.load(\"../gmn_config/model64_5.pth\"))\n",
    "gmn.to(device)\n",
    "gmn.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import torch\n",
    "from torch.nn import Linear\n",
    "\n",
    "import torch_geometric\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.nn import GCNConv, GraphConv\n",
    "from torch_geometric import utils\n",
    "from torch_geometric.nn import Sequential\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from utils.eval_metrics import *\n",
    "\n",
    "torch.manual_seed(1)\n",
    "torch.cuda.manual_seed(1)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'PubMed'\n",
    "path = osp.join('..', 'data', dataset)\n",
    "dataset = Planetoid(path, dataset, transform=T.NormalizeFeatures())\n",
    "data = dataset[0]\n",
    "\n",
    "delta = 0.85\n",
    "edge_index, edge_weight = utils.get_laplacian(data.edge_index, data.edge_weight, normalization='sym')\n",
    "L = utils.to_dense_adj(edge_index, edge_attr=edge_weight)\n",
    "A = torch.eye(data.num_nodes) - delta*L\n",
    "data.edge_index, data.edge_weight = utils.dense_to_sparse(A)\n",
    "original_data = Data(x=reduce_dimensions(data.x.numpy()), edge_index=data.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS = 1e-15\n",
    "\n",
    "def just_balance_pool(x, adj, s, mask=None, normalize=True):\n",
    "    r\"\"\"The Just Balance pooling operator from the `\"Simplifying Clustering with \n",
    "    Graph Neural Networks\" <https://arxiv.org/abs/2207.08779>`_ paper\n",
    "   \n",
    "    Args:\n",
    "        x (Tensor): Node feature tensor :math:`\\mathbf{X} \\in \\mathbb{R}^{B \\times N \\times F}` \n",
    "            with batch-size :math:`B`, (maximum) number of nodes :math:`N` \n",
    "            for each graph, and feature dimension :math:`F`.\n",
    "        adj (Tensor): Symmetrically normalized adjacency tensor\n",
    "            :math:`\\mathbf{A} \\in \\mathbb{R}^{B \\times N \\times N}`.\n",
    "        s (Tensor): Assignment tensor :math:`\\mathbf{S} \\in \\mathbb{R}^{B \\times N \\times C}` \n",
    "            with number of clusters :math:`C`. The softmax does not have to be \n",
    "            applied beforehand, since it is executed within this method.\n",
    "        mask (BoolTensor, optional): Mask matrix\n",
    "            :math:`\\mathbf{M} \\in {\\{ 0, 1 \\}}^{B \\times N}` indicating\n",
    "            the valid nodes for each graph. (default: :obj:`None`)\n",
    "\n",
    "    :rtype: (:class:`Tensor`, :class:`Tensor`, :class:`Tensor`,\n",
    "        :class:`Tensor`)\n",
    "    \"\"\"\n",
    "\n",
    "    x = x.unsqueeze(0) if x.dim() == 2 else x\n",
    "    adj = adj.unsqueeze(0) if adj.dim() == 2 else adj\n",
    "    s = s.unsqueeze(0) if s.dim() == 2 else s\n",
    "\n",
    "    (batch_size, num_nodes, _), k = x.size(), s.size(-1)\n",
    "\n",
    "    s = torch.softmax(s, dim=-1)\n",
    "\n",
    "    if mask is not None:\n",
    "        mask = mask.view(batch_size, num_nodes, 1).to(x.dtype)\n",
    "        x, s = x * mask, s * mask\n",
    "\n",
    "    out = torch.matmul(s.transpose(1, 2), x)\n",
    "    out_adj = torch.matmul(torch.matmul(s.transpose(1, 2), adj), s)\n",
    "    \n",
    "    ss = torch.matmul(s.transpose(1, 2), s)\n",
    "    ss_sqrt = torch.sqrt(ss + EPS)\n",
    "    loss = torch.mean(-_rank3_trace(ss_sqrt))\n",
    "    if normalize:\n",
    "        loss = loss / torch.sqrt(torch.tensor(num_nodes * k))\n",
    "\n",
    "    ind = torch.arange(k, device=out_adj.device)\n",
    "    out_adj[:, ind, ind] = 0\n",
    "    d = torch.einsum('ijk->ij', out_adj)\n",
    "    d = torch.sqrt(d)[:, None] + EPS\n",
    "    out_adj = (out_adj / d) / d.transpose(1, 2)\n",
    "\n",
    "    return out, out_adj, loss\n",
    "\n",
    "\n",
    "def _rank3_trace(x):\n",
    "    return torch.einsum('ijj->i', x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, \n",
    "                 mp_units,\n",
    "                 mp_act,\n",
    "                 in_channels, \n",
    "                 n_clusters, \n",
    "                 mlp_units=[],\n",
    "                 mlp_act=\"Identity\"):\n",
    "        super().__init__()\n",
    "        \n",
    "        mp_act = getattr(torch.nn, mp_act)(inplace=True)\n",
    "        mlp_act = getattr(torch.nn, mlp_act)(inplace=True)\n",
    "        \n",
    "        mp = [\n",
    "            (GCNConv(in_channels, mp_units[0], normalize=False, cached=False), 'x, edge_index, edge_weight -> x'),\n",
    "            mp_act\n",
    "        ]\n",
    "        for i in range(len(mp_units)-1):\n",
    "            mp.append((GCNConv(mp_units[i], mp_units[i+1], normalize=False, cached=False), 'x, edge_index, edge_weight -> x'))\n",
    "            mp.append(mp_act)\n",
    "        self.mp = Sequential('x, edge_index, edge_weight', mp)\n",
    "        out_chan = mp_units[-1]\n",
    "        \n",
    "        self.mlp = torch.nn.Sequential()\n",
    "        for units in mlp_units:\n",
    "            self.mlp.append(Linear(out_chan, units))\n",
    "            out_chan = units\n",
    "            self.mlp.append(mlp_act)\n",
    "        self.mlp.append(Linear(out_chan, n_clusters))\n",
    "        \n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight, l_value):\n",
    "        x = self.mp(x, edge_index, edge_weight)\n",
    "        s = self.mlp(x)\n",
    "        adj = utils.to_dense_adj(edge_index, edge_attr=edge_weight)\n",
    "        x_pooled, adj_pooled, b_loss = just_balance_pool(x, adj, s)\n",
    "        \n",
    "        if l_value != 0.0:\n",
    "            edge_index_pool = utils.dense_to_sparse(adj_pooled)[0]\n",
    "            clustered_data = torch_geometric.data.Data(x=x_pooled[0], edge_index=edge_index_pool)\n",
    "            sim = similarity(gmn, config, original_data, clustered_data)\n",
    "            sim_loss = l_value * ((1 - sim)/2)\n",
    "            # sim_loss = l_value * (1-sim)\n",
    "        else:\n",
    "            sim_loss = 0.0\n",
    "        \n",
    "        return torch.softmax(s, dim=-1), b_loss + sim_loss, x_pooled, adj_pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data = data.to(device)\n",
    "model = Net([64]*10, \"ReLU\", dataset.num_features, dataset.num_classes, [16], \"ReLU\").to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\n",
    "\n",
    "\n",
    "def train(model, optimizer, l_value = 0.0, clip = False):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    _, loss, _, _ = model(data.x, data.edge_index, data.edge_weight, l_value)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if clip:\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 10.0)\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, l_value = 0.0):\n",
    "    model.eval()\n",
    "    clust, _, x_pooled, adj_pooled = model(data.x, data.edge_index, data.edge_weight, l_value)\n",
    "    edge_index_pool = utils.dense_to_sparse(adj_pooled)[0]\n",
    "    clustered_data = torch_geometric.data.Data(x=x_pooled[0], edge_index=edge_index_pool)\n",
    "    sim = similarity(gmn, config, original_data, clustered_data)\n",
    "    acc, nmi, ari = eval_metrics(data.y.cpu(), clust.max(1)[1].cpu())\n",
    "    return acc, nmi, ari, sim\n",
    "\n",
    "patience = 50\n",
    "best_nmi = 0\n",
    "losses = []\n",
    "nmis = []\n",
    "accs = []\n",
    "aris = []\n",
    "sims = []\n",
    "for epoch in range(0, 751):\n",
    "    train_loss = train(model, optimizer)\n",
    "    if epoch % 50 == 0:\n",
    "        acc, nmi, ari, sim = test(model)\n",
    "        losses.append(train_loss)\n",
    "        accs.append(acc)\n",
    "        nmis.append(nmi)\n",
    "        aris.append(ari)\n",
    "        sims.append(sim)\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {train_loss:.4f}, NMI: {nmi:.3f}, ACC: {acc:.3f}, ARI: {ari:.3f}, SIM: {sim.item()}')\n",
    "        \n",
    "torch.save(model.state_dict(), \"jbgnn.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"jbgnn.pth\"))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "new_losses = []\n",
    "new_nmis = []\n",
    "new_accs = []\n",
    "new_aris = []\n",
    "new_sims = []\n",
    "for epoch in range(0, 751):\n",
    "    train_loss = train(model, optimizer, 0.01, True)\n",
    "    if epoch % 50 == 0:\n",
    "        acc, nmi, ari, sim = test(model, 0.01)\n",
    "        new_losses.append(train_loss)\n",
    "        new_accs.append(acc)\n",
    "        new_nmis.append(nmi)\n",
    "        new_aris.append(ari)\n",
    "        new_sims.append(sim)\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {train_loss:.4f}, NMI: {nmi:.3f}, ACC: {acc:.3f}, ARI: {ari:.3f}, SIM: {sim.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming losses, nmis, accs, aris, and sims are lists that you've populated in your loop at every 50 epochs\n",
    "# For example:\n",
    "# losses = [...]\n",
    "# nmis = [...]\n",
    "# accs = [...]\n",
    "# aris = [...]\n",
    "# sims = [...]\n",
    "\n",
    "# Since you're recording metrics every 50 epochs\n",
    "epochs = range(0, 1551, 50)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(epochs, losses+new_losses, label='Loss')\n",
    "plt.plot(epochs, nmis+new_nmis, label='NMI')\n",
    "plt.plot(epochs, accs+new_accs, label='ACC')\n",
    "plt.plot(epochs, aris+new_aris, label='ARI')\n",
    "plt.plot(epochs, sims+new_sims, label='SIM')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Metrics')\n",
    "plt.title('JBGNN')\n",
    "plt.xticks(range(0, 1551, 100))  # Set x-ticks to match your recording intervals\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
