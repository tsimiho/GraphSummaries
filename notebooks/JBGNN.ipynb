{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import torch\n",
    "from torch.nn import Linear\n",
    "\n",
    "import torch_geometric\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric import utils\n",
    "from torch_geometric.nn import Sequential\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from utils.eval_metrics import *\n",
    "\n",
    "torch.manual_seed(1)\n",
    "torch.cuda.manual_seed(1)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'Cora'\n",
    "path = osp.join('..', 'data', dataset)\n",
    "dataset = Planetoid(path, dataset, transform=T.NormalizeFeatures())\n",
    "data = dataset[0]\n",
    "\n",
    "delta = 0.85\n",
    "edge_index, edge_weight = utils.get_laplacian(data.edge_index, data.edge_weight, normalization='sym')\n",
    "L = utils.to_dense_adj(edge_index, edge_attr=edge_weight)\n",
    "A = torch.eye(data.num_nodes) - delta*L\n",
    "data.edge_index, data.edge_weight = utils.dense_to_sparse(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS = 1e-15\n",
    "\n",
    "def just_balance_pool(x, adj, s, mask=None, normalize=True):\n",
    "    r\"\"\"The Just Balance pooling operator from the `\"Simplifying Clustering with \n",
    "    Graph Neural Networks\" <https://arxiv.org/abs/2207.08779>`_ paper\n",
    "   \n",
    "    Args:\n",
    "        x (Tensor): Node feature tensor :math:`\\mathbf{X} \\in \\mathbb{R}^{B \\times N \\times F}` \n",
    "            with batch-size :math:`B`, (maximum) number of nodes :math:`N` \n",
    "            for each graph, and feature dimension :math:`F`.\n",
    "        adj (Tensor): Symmetrically normalized adjacency tensor\n",
    "            :math:`\\mathbf{A} \\in \\mathbb{R}^{B \\times N \\times N}`.\n",
    "        s (Tensor): Assignment tensor :math:`\\mathbf{S} \\in \\mathbb{R}^{B \\times N \\times C}` \n",
    "            with number of clusters :math:`C`. The softmax does not have to be \n",
    "            applied beforehand, since it is executed within this method.\n",
    "        mask (BoolTensor, optional): Mask matrix\n",
    "            :math:`\\mathbf{M} \\in {\\{ 0, 1 \\}}^{B \\times N}` indicating\n",
    "            the valid nodes for each graph. (default: :obj:`None`)\n",
    "\n",
    "    :rtype: (:class:`Tensor`, :class:`Tensor`, :class:`Tensor`,\n",
    "        :class:`Tensor`)\n",
    "    \"\"\"\n",
    "\n",
    "    x = x.unsqueeze(0) if x.dim() == 2 else x\n",
    "    adj = adj.unsqueeze(0) if adj.dim() == 2 else adj\n",
    "    s = s.unsqueeze(0) if s.dim() == 2 else s\n",
    "\n",
    "    (batch_size, num_nodes, _), k = x.size(), s.size(-1)\n",
    "\n",
    "    s = torch.softmax(s, dim=-1)\n",
    "\n",
    "    if mask is not None:\n",
    "        mask = mask.view(batch_size, num_nodes, 1).to(x.dtype)\n",
    "        x, s = x * mask, s * mask\n",
    "\n",
    "    out = torch.matmul(s.transpose(1, 2), x)\n",
    "    out_adj = torch.matmul(torch.matmul(s.transpose(1, 2), adj), s)\n",
    "    \n",
    "    ss = torch.matmul(s.transpose(1, 2), s)\n",
    "    ss_sqrt = torch.sqrt(ss + EPS)\n",
    "    loss = torch.mean(-_rank3_trace(ss_sqrt))\n",
    "    if normalize:\n",
    "        loss = loss / torch.sqrt(torch.tensor(num_nodes * k))\n",
    "\n",
    "    ind = torch.arange(k, device=out_adj.device)\n",
    "    out_adj[:, ind, ind] = 0\n",
    "    d = torch.einsum('ijk->ij', out_adj)\n",
    "    d = torch.sqrt(d)[:, None] + EPS\n",
    "    out_adj = (out_adj / d) / d.transpose(1, 2)\n",
    "\n",
    "    return out, out_adj, loss\n",
    "\n",
    "\n",
    "def _rank3_trace(x):\n",
    "    return torch.einsum('ijj->i', x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, \n",
    "                 mp_units,\n",
    "                 mp_act,\n",
    "                 in_channels, \n",
    "                 n_clusters, \n",
    "                 mlp_units=[],\n",
    "                 mlp_act=\"Identity\"):\n",
    "        super().__init__()\n",
    "        \n",
    "        mp_act = getattr(torch.nn, mp_act)(inplace=True)\n",
    "        mlp_act = getattr(torch.nn, mlp_act)(inplace=True)\n",
    "        \n",
    "        mp = [\n",
    "            (GCNConv(in_channels, mp_units[0], normalize=False, cached=False), 'x, edge_index, edge_weight -> x'),\n",
    "            mp_act\n",
    "        ]\n",
    "        for i in range(len(mp_units)-1):\n",
    "            mp.append((GCNConv(mp_units[i], mp_units[i+1], normalize=False, cached=False), 'x, edge_index, edge_weight -> x'))\n",
    "            mp.append(mp_act)\n",
    "        self.mp = Sequential('x, edge_index, edge_weight', mp)\n",
    "        out_chan = mp_units[-1]\n",
    "        \n",
    "        self.mlp = torch.nn.Sequential()\n",
    "        for units in mlp_units:\n",
    "            self.mlp.append(Linear(out_chan, units))\n",
    "            out_chan = units\n",
    "            self.mlp.append(mlp_act)\n",
    "        self.mlp.append(Linear(out_chan, n_clusters))\n",
    "        \n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        x = self.mp(x, edge_index, edge_weight)\n",
    "        s = self.mlp(x)\n",
    "        adj = utils.to_dense_adj(edge_index, edge_attr=edge_weight)\n",
    "        x_pooled, adj_pooled, b_loss = just_balance_pool(x, adj, s)\n",
    "        \n",
    "        return torch.softmax(s, dim=-1), b_loss, x_pooled, adj_pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 050, Loss: -0.3780, NMI: 0.000, ACC: 0.302\n",
      "Epoch: 100, Loss: -0.3782, NMI: 0.000, ACC: 0.302\n",
      "Epoch: 150, Loss: -0.3909, NMI: 0.000, ACC: 0.302\n",
      "Epoch: 200, Loss: -0.3949, NMI: 0.000, ACC: 0.302\n",
      "Epoch: 250, Loss: -0.3972, NMI: 0.000, ACC: 0.302\n",
      "Epoch: 300, Loss: -0.4010, NMI: 0.000, ACC: 0.302\n",
      "Epoch: 350, Loss: -0.4392, NMI: 0.037, ACC: 0.322\n",
      "Epoch: 400, Loss: -0.4850, NMI: 0.207, ACC: 0.403\n",
      "Epoch: 450, Loss: -0.4946, NMI: 0.230, ACC: 0.403\n",
      "Epoch: 500, Loss: -0.5558, NMI: 0.253, ACC: 0.390\n",
      "Epoch: 550, Loss: -0.5759, NMI: 0.255, ACC: 0.391\n",
      "Epoch: 600, Loss: -0.6155, NMI: 0.354, ACC: 0.469\n",
      "Epoch: 650, Loss: -0.6356, NMI: 0.359, ACC: 0.473\n",
      "Epoch: 700, Loss: -0.6375, NMI: 0.361, ACC: 0.480\n",
      "Epoch: 750, Loss: -0.6398, NMI: 0.361, ACC: 0.479\n",
      "Epoch: 800, Loss: -0.6412, NMI: 0.359, ACC: 0.475\n",
      "Epoch: 850, Loss: -0.6442, NMI: 0.353, ACC: 0.467\n",
      "Epoch: 900, Loss: -0.6472, NMI: 0.352, ACC: 0.464\n",
      "Epoch: 950, Loss: -0.7276, NMI: 0.341, ACC: 0.462\n",
      "Epoch: 1000, Loss: -0.9002, NMI: 0.336, ACC: 0.468\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data = data.to(device)\n",
    "model = Net([64]*10, \"ReLU\", dataset.num_features, dataset.num_classes, [16], \"ReLU\").to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    _, loss, _, _ = model(data.x, data.edge_index, data.edge_weight)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test():\n",
    "    model.eval()\n",
    "    clust, _, _, _ = model(data.x, data.edge_index, data.edge_weight)\n",
    "    return eval_metrics(data.y.cpu(), clust.max(1)[1].cpu())\n",
    "\n",
    "patience = 50\n",
    "best_nmi = 0\n",
    "for epoch in range(1, 1001):\n",
    "    train_loss = train()\n",
    "    acc, nmi = test()\n",
    "    if epoch % 50 == 0:\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {train_loss:.4f}, NMI: {nmi:.3f}, ACC: {acc:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder= {'node_hidden_sizes': [64], 'node_feature_dim': 1, 'edge_hidden_sizes': [4]}\n",
      "aggregator= {'node_hidden_sizes': [128], 'graph_transform_sizes': [128], 'input_size': [64], 'gated': True, 'aggregation_type': 'sum'}\n",
      "graph_embedding_net= {'node_state_dim': 64, 'edge_state_dim': 4, 'edge_hidden_sizes': [128, 128], 'node_hidden_sizes': [128], 'n_prop_layers': 5, 'share_prop_params': True, 'edge_net_init_scale': 0.1, 'node_update_type': 'gru', 'use_reverse_direction': True, 'reverse_dir_param_different': False, 'layer_norm': False, 'prop_type': 'matching'}\n",
      "graph_matching_net= {'node_state_dim': 64, 'edge_state_dim': 4, 'edge_hidden_sizes': [128, 128], 'node_hidden_sizes': [128], 'n_prop_layers': 5, 'share_prop_params': True, 'edge_net_init_scale': 0.1, 'node_update_type': 'gru', 'use_reverse_direction': True, 'reverse_dir_param_different': False, 'layer_norm': False, 'prop_type': 'matching', 'similarity': 'dotproduct'}\n",
      "model_type= matching\n",
      "data= {'problem': 'graph_edit_distance', 'dataset_params': {'n_nodes_range': [20, 20], 'p_edge_range': [0.2, 0.2], 'n_changes_positive': 1, 'n_changes_negative': 2, 'validation_dataset_size': 1000}}\n",
      "training= {'batch_size': 20, 'learning_rate': 0.0001, 'mode': 'pair', 'loss': 'cosine', 'margin': 1.0, 'graph_vec_regularizer_weight': 1e-06, 'clip_value': 10.0, 'n_training_steps': 100000, 'print_after': 100, 'eval_after': 10}\n",
      "evaluation= {'batch_size': 20}\n",
      "seed= 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GraphMatchingNet(\n",
       "  (_encoder): GraphEncoder(\n",
       "    (MLP1): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "    )\n",
       "    (MLP2): Sequential(\n",
       "      (0): Linear(in_features=4, out_features=4, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (_aggregator): GraphAggregator(\n",
       "    (MLP1): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "    )\n",
       "    (MLP2): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (_prop_layers): ModuleList(\n",
       "    (0-4): 5 x GraphPropMatchingLayer(\n",
       "      (_message_net): Sequential(\n",
       "        (0): Linear(in_features=132, out_features=128, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (_reverse_message_net): Sequential(\n",
       "        (0): Linear(in_features=132, out_features=128, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (GRU): GRU(192, 64)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../gmn_config/'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from gmn_config.graph_utils import *\n",
    "\n",
    "from gmn_config.evaluation import compute_similarity, auc\n",
    "from gmn_config.loss import pairwise_loss, triplet_loss\n",
    "from gmn_config.gmn_utils import *\n",
    "from gmn_config.configure_cosine import *\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "\n",
    "# Print configure\n",
    "config = get_default_config()\n",
    "for k, v in config.items():\n",
    "    print(\"%s= %s\" % (k, v))\n",
    "\n",
    "# Set random seeds\n",
    "seed = config[\"seed\"]\n",
    "random.seed(seed)\n",
    "np.random.seed(seed + 1)\n",
    "torch.manual_seed(seed + 2)\n",
    "torch.backends.cudnn.deterministic = False\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "\n",
    "training_set, validation_set = build_datasets(config)\n",
    "\n",
    "if config[\"training\"][\"mode\"] == \"pair\":\n",
    "    training_data_iter = training_set.pairs(config[\"training\"][\"batch_size\"])\n",
    "    first_batch_graphs, _ = next(training_data_iter)\n",
    "else:\n",
    "    training_data_iter = training_set.triplets(config[\"training\"][\"batch_size\"])\n",
    "    first_batch_graphs = next(training_data_iter)\n",
    "\n",
    "node_feature_dim = first_batch_graphs.node_features.shape[-1]\n",
    "edge_feature_dim = first_batch_graphs.edge_features.shape[-1]\n",
    "\n",
    "gmn, optimizer = build_model(config, node_feature_dim, edge_feature_dim)\n",
    "gmn.load_state_dict(torch.load(\"../gmn_config/model64new.pth\"))\n",
    "gmn.to(device)\n",
    "gmn.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3520, grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "_, _, x_pool, adj_pool = model(data.x, data.edge_index, data.edge_weight)\n",
    "edge_index_pool = utils.dense_to_sparse(adj_pool)[0]\n",
    "clustered_data = torch_geometric.data.Data(x=x_pool[0], edge_index=edge_index_pool)\n",
    "original_data = Data(x=reduce_dimensions(data.x.numpy()), edge_index=data.edge_index)\n",
    "sim = similarity(gmn, config, original_data, clustered_data)\n",
    "print(sim)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
